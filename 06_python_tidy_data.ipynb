{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer**: functions and methods used in this notebook are covered in the next lessons. Here it is only to generate the tables to show different versions of storing data. If you want to study these examples, come back after the next few notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizing data\n",
    "\n",
    "Topics we will discuss in this lesson are closely related to database management. The concept of *tidy data* was introduced by Hadley Wickham (Chief scientist in **R** project) and was inspired by databases. It turns out that scientists and statisticians can benifit very much from the same concepts. In particular, structuring your data in a tidy way will facilitate any type of analysis you want to do.\n",
    "\n",
    "The core ideas in this lesson are taken from Hadley Wickham's seminal paper \"Tidy data\" [1], which IMO every person who works with complex datasets should read. Some examples in this notebook are from that paper, while others I made up myself.\n",
    "\n",
    "[1] Wickham, H. (2014). Tidy data. Journal of Statistical Software, 59(10), 1-23."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidying: structuring datasets to facilitate analysis\n",
    "\n",
    "The principles of tidy data provide a standard way to organize data values within a dataset. Current tools often require translation: you have to spend time munging the output from one tool so you can input it into another. Tidy datasets and tools for them work hand in hand to make data analysis easier, allowing you to focus on the interesting domain problem, not on the uninteresting logistics of data.\n",
    "\n",
    "Let's start with an example.\n",
    "\n",
    "Consider the following 2 ways of presenting the same toy data. Think about whether there is any difference how we organize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untidy = pd.DataFrame({'treatment_a':[np.nan, 16, 3],'treatment_b':[2,11,1]}, \n",
    "                      index=['John Smith', 'Jane Doe','Mary Johnson'])\n",
    "untidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untidy.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset is a collection of values, usually either numbers (if quantitative) or strings (if\n",
    "qualitative). Values are organized in two ways. Every value belongs to a variable and an\n",
    "observation. **A variable contains all values that measure the same underlying attribute** (like\n",
    "height, temperature, duration) across units. **An observation contains all values measured on\n",
    "the same unit** (like a person, or a day, or a race) across attributes.\n",
    "\n",
    "Let's restructure the dataset in the following (*tidy*, as we will learn later) way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untidy.index.name = 'person'\n",
    "untidy.columns.name = 'treatment'\n",
    "tidy = pd.melt(untidy.reset_index(),id_vars=['person'],value_name='result')\n",
    "tidy['treatment'].replace({'treatment_a':'a','treatment_b':'b'}, inplace=True)\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes it clear that the\n",
    "dataset contains 18 values representing three variables and six observations. The variables\n",
    "are:\n",
    "1. person, with three possible values (John Smith, Mary Johnson, and Jane Doe).\n",
    "2. treatment, with two possible values (a and b).\n",
    "3. result, with five or six values depending on how you think of the missing value (â€”,\n",
    "16, 3, 2, 11, 1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy data\n",
    "Tidy data is a standard way of mapping the meaning of a dataset to its structure. A dataset is\n",
    "messy or tidy depending on how rows, columns and tables are matched up with observations,\n",
    "variables and types. Core principles of tidy data are simple:\n",
    "1. Each **variable** forms a **column**\n",
    "2. Each **observation** forms a **row**\n",
    "3. Each **type of observational unit** forms a **table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_untidy = pd.read_csv(os.path.join('data','pew.csv'))\n",
    "income_untidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_untidy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here there is a `religion` column, which forms a separate variable, but all other columns actually contain the same variable -- `count`. `income` forms another (\"groupping\") variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "income_tidy = pd.melt(income_untidy,id_vars=['religion'],var_name='income',value_name='count')\n",
    "income_tidy.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_tidy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things I can do with untidy as well as with tidy, but what if I wanted to change to proportion for each religion to have certain income, but keep the count as well (because it tells me how precise is the measurement and is need to calculating statistics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "income_tidy['prop_income'] = income_tidy.groupby('religion')['count'].transform(lambda x: x/x.sum()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_tidy.loc[income_tidy['religion']=='Agnostic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_tidy.loc[income_tidy['income']=='>150k'].sort_values('prop_income', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can also easily add proportion of religions for each income group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "income_tidy['prop_religion'] = income_tidy.groupby('income')['count'].transform(lambda x: x/x.sum()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_tidy.loc[income_tidy['religion']=='Agnostic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_tidy.loc[income_tidy['income']=='>150k'].sort_values('prop_religion',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages of tidy data:\n",
    "\n",
    "1. Adding new variables is easy and straightforward. It doesn't complicate the data structure or analysis.\n",
    "\n",
    "2. When you have structurally missing data (like number of pregnancies for males), you can throw out some observations (in untidy table they will have to exist, although they make no sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "billboard_untidy = pd.read_csv(os.path.join('data','billboard.csv'))\n",
    "billboard_untidy[billboard_untidy.columns[:10]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_untidy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I wanted to look at, say, all songs which reached the 1st place, and see which song did it faster, there is no easy way of doing it in this data form. However, it is very easy to do with tidy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_tidy = pd.melt(billboard_untidy,id_vars=['year','artist',\n",
    "                                                   'track','time','genre',\n",
    "                                                   'date.entered','date.peaked'],\n",
    "                        var_name='week',value_name='rank')\n",
    "\n",
    "def keep_num(string):\n",
    "    digits_list = [c for c in string if c.isdigit()]\n",
    "    digits_string = ''.join(digits_list)\n",
    "    number = int(digits_string)\n",
    "    return number\n",
    "\n",
    "billboard_tidy['week'].replace({s:keep_num(s) for s in billboard_tidy['week']}, inplace=True)\n",
    "billboard_tidy.rename(columns={'date.entered':'entered', \n",
    "                               'date.peaked':'peaked'}, \n",
    "                      inplace=True)\n",
    "\n",
    "billboard_tidy['entered'] = pd.to_datetime(billboard_tidy['entered'])\n",
    "billboard_tidy['peaked'] = pd.to_datetime(billboard_tidy['peaked'])\n",
    "\n",
    "billboard_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_tidy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "billboard_tidy.loc[billboard_tidy['rank']==1].sort_values('week').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During tidying, each type of observational unit should be stored in its own table. This\n",
    "is closely related to the idea of database normalization, where each fact is expressed in only\n",
    "one place. If this is not done, it is possible for inconsistencies to occur.\n",
    "\n",
    "The Billboard dataset described before actually contains observations on two types of\n",
    "observational units: the song and its rank in each week. This manifests itself through the\n",
    "duplication of facts about the song: `year`, `artist`, `track`, `time`, `genre`, `entered` and `peaked` are repeated for every `song` in each `week`.\n",
    "\n",
    "But this examples is a bit complicated, so let's look at another one, which can be quite frequent in research. Afterwards we will get back to the billboard dataset to reorganize it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate subjects data\n",
    "\n",
    "# number of subjects\n",
    "n = 10\n",
    "\n",
    "subjects_id = np.arange(n)\n",
    "\n",
    "# if you have module `names`, it will generate names with it;\n",
    "# otherwise, names will be just tokens 'Name Surname #'\n",
    "try:\n",
    "    import names\n",
    "    subjects_names = []\n",
    "    subjects_gender = []\n",
    "    for g in ['male','female']:\n",
    "        for i in np.arange(n/2):\n",
    "            subjects_names.append(names.get_full_name(gender=g))\n",
    "            subjects_gender.append(g)\n",
    "            \n",
    "except:\n",
    "    subjects_names = ['Name Surname {}'.format(i+1) for i in range(n)]\n",
    "    subjects_gender = ['male','female']*int(n/2)\n",
    "\n",
    "subjects_age = np.random.randint(15, 85, size=n)\n",
    "\n",
    "task_names = ['memory_matrix', 'labyrinth', 'math_game', 'names_memory', 'survey_score', \n",
    "              'session_1', 'session_2', 'session_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set subjects data into dataframe\n",
    "df = pd.DataFrame({'id': subjects_id, 'name': subjects_names, 'gender': subjects_gender, 'age': subjects_age})\n",
    "\n",
    "# generate scores for each task\n",
    "for subj_id in df.index:\n",
    "    for task in task_names:\n",
    "        df.at[subj_id, task] = np.random.randint(100-df.at[subj_id, 'age'], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_tidy_1 = pd.melt(df, id_vars=['age','gender','name','id'],var_name='task',value_name='score')\n",
    "df_tidy_1.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy_1.groupby('task')['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy_1.groupby(['gender','task'])['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy_1.groupby('age')['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df_tidy_1.groupby('age')['score'].mean().plot(marker='o',linestyle='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some applications this is fine. However, if I am interested in the sessions' scores, it is somewhat tedious to work with them. In a way, score on every task is actually a separate variable, because they are not directly comparable. Except for sessions' scores -- they are on the same task and they are directly comparable. How to organize this then? We could treat other scores, except for sessions, as separate variables, and keep scores for sessions and session # as another 2 variables, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy_2 = pd.melt(df, id_vars=['age','gender','name','id','memory_matrix', \n",
    "                     'labyrinth', 'math_game', 'names_memory', 'survey_score'],\n",
    "                    var_name='session',value_name='score')\n",
    "\n",
    "df_tidy_2['session'].replace({s:int(s[-1]) for s in df_tidy_2['session'].unique()}, inplace=True)\n",
    "df_tidy_2.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy_2.groupby('math_game')['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy_2.groupby('math_game')['score'].mean().plot(marker='o',linestyle='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy_2.groupby(['name','score'])['survey_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy_2.groupby(['name'])['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_names[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_df = df[['age','gender','name','id','memory_matrix', 'labyrinth', \n",
    "              'math_game', 'names_memory', 'survey_score']].set_index('id', drop='True')\n",
    "subj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.melt(df[['id','session_1','session_2','session_3']],id_vars='id',var_name='session',value_name='score')\n",
    "scores_df['session'].replace({s:int(s[-1]) for s in scores_df['session'].unique()}, inplace=True)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(subj_df, scores_df, left_index=True, right_on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get back to the billboard dataset, and tidy it in the same manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "billboard_untidy.index.name = 'id'\n",
    "\n",
    "songs_keys = billboard_untidy.keys()[:7]\n",
    "songs_df = billboard_untidy[songs_keys]\n",
    "songs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_keys = billboard_untidy.keys()[7:]\n",
    "rank_df = billboard_untidy[rank_keys]\n",
    "rank_df.index.name = 'id'\n",
    "rank_df = rank_df.reset_index()\n",
    "rank_df = pd.melt(rank_df, id_vars='id', var_name = 'week', value_name = 'rank')\n",
    "rank_df['week'].replace({s:keep_num(s) for s in rank_df['week']}, inplace=True)\n",
    "rank_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(songs_df, rank_df, left_index=True, right_on='id').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(songs_df, rank_df, left_index=True, right_on='id').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afterword\n",
    "\n",
    "Tidy data is only worthwhile if it\n",
    "makes analysis easier. **Tidy tools** take tidy datasets as input\n",
    "and return tidy datasets as output. **Tidy tools** are useful because the output of one tool\n",
    "can be used as the input to another. This allows you to simply and easily compose multiple\n",
    "tools to solve a problem. Tidy data also ensures that variables are stored in a consistent,\n",
    "explicit manner. This makes each tool simpler, because it does not need a Swiss Army knife\n",
    "of parameters for dealing with different dataset structures.\n",
    "\n",
    "Tools can be messy for two reasons: either they take messy datasets as input (**messy-input\n",
    "tools**) or they produce messy datasets as output (**messy-output tools**). Messy-input tools are\n",
    "typically more complicated than tidy-input tools because they need to include some parts of\n",
    "the tidying process. This can be useful for common types of messy datasets, but it typically\n",
    "makes the function more complex, harder to use and harder to maintain. Messy-output tools\n",
    "are frustrating and slow down analysis because they cannot be easily composed and you must\n",
    "constantly think about how to convert from one format to another.\n",
    "\n",
    "We will see examples of messy tools and, more importantly, tidy tools in our future lessons."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
